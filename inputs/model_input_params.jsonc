{
  // ==========================================================================
  // Spectral Prediction Model Configuration
  // ==========================================================================
  // Configuration for predicting spectral sequences from atmospheric profiles
  // ==========================================================================

  // ==========================================================================
  // Data Configuration
  // ==========================================================================
  
  // Input variables (features) for the model - atmospheric profile inputs
  "input_variables": [
    "pressure",       // Atmospheric pressure at each layer
    "temperature",    // Temperature at each layer
    "orbital_sep"    // Orbital separation
  ],
  
  // Target variables to predict - spectral outputs
  "target_variables": [
    "thermal_net_flux",
    "reflected_net_flux"    
  ],
  
  // Coordinate variables - define the spectral grid points
  "coordinate_variable": [
    "pressure"    
  ],
  
  // Pressure range configuration for input profiles
  "pressure_range": {
    "min": 1e-5,      // Minimum pressure (bars)
    "max": 100.0,     // Maximum pressure (bars)
    "points": 50     // Number of pressure levels (input sequence length)
  },
  
  // Fraction of data to use (1.0 = use all data)
  "frac_of_data": 1.0,

  // ==========================================================================
  // Data Normalization
  // ==========================================================================
  "normalization": {
    // Specific normalization methods for individual variables
    "key_methods": {
      "pressure": "log-min-max",
      "thermal_net_flux": "custom",
      "reflected_net_flux": "custom"
    },
    // Default method for variables not specified in key_methods
    "default_method": "iqr",
    // Whether to clip outliers before normalization
    "clip_outliers_before_scaling": false
  },

  // ==========================================================================
  // Memory Efficiency Parameters
  // ==========================================================================
  
  // Enable mixed precision for memory savings
  "use_mixed_precision": true,
  "use_amp": true,
  
  // Chunk size for processing long sequences
  "chunk_size": 5000,

  // ==========================================================================
  // Model Architecture
  // ==========================================================================
  
  // Hidden dimension size
  "hidden_dim": 256,
  
  // Number of attention heads (must divide hidden_dim evenly)
  "nhead": 4,
  
  // Number of transformer layers
  "num_layers": 8,
  
  // Feedforward dimension (typically 2-4x hidden_dim)
  "dim_feedforward": 1024,
  
  // Positional encoding dimension for coordinates
  "pos_encoding_dim": 64,
  
  // Maximum frequency for positional encoding
  "max_freq": 50.0,
  
  // Positional encoding type: "sine" (fixed sinusoidal) or "learned" (trainable)
  "pos_encoding_type": "sine",

  // Integration method for global and sequential features
  // "add" (simple addition), "film" (feature-wise linear modulation), "concat" (concatenation)
  "integration_method": "film",
  
  // Use torch.compile for acceleration (if available)
  "use_torch_compile": true,
  
  // Stochastic depth rate for regularization (0.0 = disabled)
  "stochastic_depth_rate": 0.1,

  // ==========================================================================
  // Regularization
  // ==========================================================================
  
  // Dropout probability
  "dropout": 0.05,
  
  // L2 regularization coefficient
  "weight_decay": 1e-5,
  
  // Loss function: "mse", "l1", or "smooth_l1"
  "loss_function": "mse",

  // ==========================================================================
  // Training Configuration
  // ==========================================================================
  
  // Number of training epochs
  "epochs": 60,
  
  // Batch size for training
  "batch_size": 16,
  
  // Number of worker processes for data loading
  "num_workers": 4,
  
  // Early stopping patience (epochs without improvement before stopping)
  "early_stopping_patience": 20,
  
  // Minimum improvement to count as progress for early stopping
  "min_delta": 1e-6,
  
  // Maximum gradient norm for gradient clipping
  "gradient_clip_val": 1.0,
  
  // Number of epochs to wait before reducing learning rate
  "lr_patience": 5,

  // ==========================================================================
  // Optimizer Configuration
  // ==========================================================================
  
  // Optimizer type: "adamw", "adam", "sgd"
  "optimizer": "adamw",
  
  // Base learning rate
  "learning_rate": 3e-4,
  
  // Minimum learning rate
  "min_lr": 1e-7,
  
  // Learning rate decay factor
  "gamma": 0.5,
  
  // Random seed for reproducibility
  "random_seed": 42
}