2025-07-17 12:13:32,413 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-17 12:13:32,413 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-17 12:13:32,414 | INFO     | utils - Generating new dataset splits...
2025-07-17 12:13:32,440 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-17 12:13:32,556 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-17 12:13:32,556 | INFO     | preprocess - One or more processed split directories missing or empty. Proceeding with preprocessing.
2025-07-17 12:13:32,556 | INFO     | preprocess - Starting data preprocessing...
2025-07-17 12:13:32,556 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-17 12:13:32,556 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-17 12:13:32,556 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-18 12:26:26,256 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-18 12:26:26,256 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-18 12:26:26,256 | INFO     | utils - Generating new dataset splits...
2025-07-18 12:26:26,278 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-18 12:26:26,384 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-18 12:26:26,385 | INFO     | preprocess - One or more processed split directories missing or empty. Proceeding with preprocessing.
2025-07-18 12:26:26,385 | INFO     | preprocess - Starting data preprocessing...
2025-07-18 12:26:26,385 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-18 12:26:26,385 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-18 12:26:26,385 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-18 12:27:14,729 | INFO     | normalizer - Finished statistics calculation in 48.34s.
2025-07-18 12:27:14,887 | INFO     | normalizer - Statistics calculation complete.
2025-07-18 12:27:14,888 | INFO     | preprocess - Normalization metadata computed and saved in 48.50s.
2025-07-18 12:27:14,892 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-18 12:28:04,294 | INFO     | preprocess - Completed train split in 49.41s.
2025-07-18 12:28:04,296 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-18 12:28:14,424 | INFO     | preprocess - Completed val split in 10.13s.
2025-07-18 12:28:14,426 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-18 12:28:24,460 | INFO     | preprocess - Completed test split in 10.04s.
2025-07-18 12:28:24,461 | INFO     | preprocess - Preprocessing completed in 118.08s.
2025-07-18 12:28:24,573 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-18 12:28:24,573 | ERROR    | __main__ - Pipeline error: Missing directories in data/processed/train: {'targets', 'sequence_inputs', 'globals'}
2025-07-19 11:34:52,495 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-19 11:34:52,495 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-19 11:34:52,495 | INFO     | utils - Generating new dataset splits...
2025-07-19 11:34:52,514 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-19 11:34:52,626 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-19 11:34:52,627 | INFO     | preprocess - One or more processed NPY directories missing. Proceeding with preprocessing.
2025-07-19 11:34:52,627 | INFO     | preprocess - Starting data preprocessing...
2025-07-19 11:34:52,627 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-19 11:34:52,627 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-19 11:34:52,627 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-19 11:35:42,046 | INFO     | normalizer - Finished statistics calculation in 49.42s.
2025-07-19 11:35:42,196 | INFO     | normalizer - Statistics calculation complete.
2025-07-19 11:35:42,198 | INFO     | preprocess - Normalization metadata computed and saved in 49.57s.
2025-07-19 11:35:42,201 | INFO     | preprocess - Processing train split (70000 profiles) into shards of size 4096...
2025-07-19 11:36:29,892 | INFO     | preprocess - Completed train split in 47.69s. Created 18 shards.
2025-07-19 11:36:29,894 | INFO     | preprocess - Processing val split (15000 profiles) into shards of size 4096...
2025-07-19 11:36:39,695 | INFO     | preprocess - Completed val split in 9.80s. Created 4 shards.
2025-07-19 11:36:39,698 | INFO     | preprocess - Processing test split (15000 profiles) into shards of size 4096...
2025-07-19 11:36:49,462 | INFO     | preprocess - Completed test split in 9.77s. Created 4 shards.
2025-07-19 11:36:49,462 | INFO     | preprocess - Preprocessing completed in 116.84s.
2025-07-19 11:36:49,574 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-19 11:36:49,580 | INFO     | dataset - AtmosphericDataset initialised: 70000 samples from data/processed/train
2025-07-19 11:36:49,580 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-19 11:36:49,581 | INFO     | dataset - AtmosphericDataset initialised: 15000 samples from data/processed/val
2025-07-19 11:36:49,581 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-19 11:36:49,582 | INFO     | dataset - AtmosphericDataset initialised: 15000 samples from data/processed/test
2025-07-19 11:36:49,582 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-19 11:36:49,586 | CRITICAL | __main__ - Unhandled exception: 'super' object has no attribute '_FiLMLayer__init'
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/main.py", line 135, in main
    trainer = ModelTrainer(
              ^^^^^^^^^^^^^
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 83, in __init__
    self._build_model()
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 165, in _build_model
    self.model = create_prediction_model(self.cfg, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 201, in create_prediction_model
    model = PredictionModel(
            ^^^^^^^^^^^^^^^^
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 97, in __init__
    self.film = FiLMLayer(global_input_dim, d_model)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 47, in __init__
    super().__init()
    ^^^^^^^^^^^^^^
AttributeError: 'super' object has no attribute '_FiLMLayer__init'
2025-07-19 11:44:35,110 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-19 11:44:35,110 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-19 11:44:35,110 | INFO     | utils - Generating new dataset splits...
2025-07-19 11:44:35,130 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-19 11:44:35,237 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-19 11:44:35,238 | INFO     | preprocess - Starting data preprocessing...
2025-07-19 11:44:35,238 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-19 11:44:35,238 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-19 11:44:35,238 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-19 11:45:24,174 | INFO     | normalizer - Finished statistics calculation in 48.94s.
2025-07-19 11:45:24,315 | INFO     | normalizer - Statistics calculation complete.
2025-07-19 11:45:24,316 | INFO     | preprocess - Normalization metadata computed and saved in 49.08s.
2025-07-19 11:45:24,319 | INFO     | preprocess - Processing train split (70000 profiles) into shards of size 4096...
2025-07-19 12:01:54,238 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-19 12:01:54,238 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-19 12:01:54,238 | INFO     | utils - Generating new dataset splits...
2025-07-19 12:01:54,258 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-19 12:01:54,366 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-19 12:01:54,367 | INFO     | preprocess - Starting data preprocessing...
2025-07-19 12:01:54,367 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-19 12:01:54,367 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-19 12:01:54,367 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-19 12:32:43,521 | INFO     | normalizer - Finished statistics calculation in 1849.15s.
2025-07-19 12:32:43,672 | INFO     | normalizer - Statistics calculation complete.
2025-07-19 12:32:43,673 | INFO     | preprocess - Normalization metadata computed and saved in 1849.31s.
2025-07-19 12:32:43,677 | INFO     | preprocess - Processing train split (70000 profiles) into shards of size 4096...
2025-07-19 13:47:49,451 | INFO     | preprocess - Completed train split in 4505.78s. Created 18 shards.
2025-07-19 13:47:49,453 | INFO     | preprocess - Processing val split (15000 profiles) into shards of size 4096...
2025-07-19 13:47:59,062 | INFO     | preprocess - Completed val split in 9.61s. Created 4 shards.
2025-07-19 13:47:59,067 | INFO     | preprocess - Processing test split (15000 profiles) into shards of size 4096...
2025-07-19 13:48:08,848 | INFO     | preprocess - Completed test split in 9.79s. Created 4 shards.
2025-07-19 13:48:08,848 | INFO     | preprocess - Preprocessing completed in 6374.48s.
2025-07-19 13:48:08,972 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-19 13:48:08,977 | INFO     | dataset - AtmosphericDataset initialised: 70000 samples from data/processed/train
2025-07-19 13:48:08,977 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-19 13:48:08,979 | INFO     | dataset - AtmosphericDataset initialised: 15000 samples from data/processed/val
2025-07-19 13:48:08,979 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-19 13:48:08,980 | INFO     | dataset - AtmosphericDataset initialised: 15000 samples from data/processed/test
2025-07-19 13:48:08,980 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-19 13:48:09,015 | INFO     | model - PredictionModel created with 4,807,181 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-19 13:48:09,036 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-19 13:48:09,036 | INFO     | model - Model moved to device: mps
2025-07-19 13:48:09,731 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-19 13:48:09,731 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-19 13:48:09,731 | INFO     | train - Effective batch size: 64 (accumulation: 1)
2025-07-19 13:48:09,770 | INFO     | train - Training for 300 epochs.
2025-07-19 21:59:49,803 | INFO     | train - E001  train:5.877e-01  val:9.129e-03  lr:1.00e-04  t:29500.0s  ↓inf
2025-07-19 21:59:49,851 | INFO     | train - Saved best model (epoch 1).
2025-07-19 21:59:50,267 | INFO     | model - Model exported successfully with torch.export.
2025-07-19 21:59:50,267 | ERROR    | train - Model export failed: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 447, in _export_model
    export_model(self.model, example, path, self.cfg)
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 278, in export_model
    test_output = exported_model(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/export/exported_program.py", line 1242, in __call__
    raise RuntimeError(
RuntimeError: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
2025-07-19 22:26:51,395 | INFO     | train - E002  train:1.960e-02  val:4.708e-03  lr:1.00e-04  t:1621.1s  ↓4.421e-03
2025-07-19 22:26:51,431 | INFO     | train - Saved best model (epoch 2).
2025-07-19 22:26:51,659 | INFO     | model - Model exported successfully with torch.export.
2025-07-19 22:26:51,659 | ERROR    | train - Model export failed: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 447, in _export_model
    export_model(self.model, example, path, self.cfg)
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 278, in export_model
    test_output = exported_model(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/export/exported_program.py", line 1242, in __call__
    raise RuntimeError(
RuntimeError: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
2025-07-19 22:54:05,725 | INFO     | train - E003  train:1.557e-02  val:3.718e-03  lr:1.00e-04  t:1634.1s  ↓9.898e-04
2025-07-19 22:54:05,760 | INFO     | train - Saved best model (epoch 3).
2025-07-19 22:54:05,986 | INFO     | model - Model exported successfully with torch.export.
2025-07-19 22:54:05,986 | ERROR    | train - Model export failed: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 447, in _export_model
    export_model(self.model, example, path, self.cfg)
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 278, in export_model
    test_output = exported_model(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/export/exported_program.py", line 1242, in __call__
    raise RuntimeError(
RuntimeError: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
2025-07-19 23:34:47,053 | INFO     | train - E004  train:1.358e-02  val:3.275e-03  lr:1.00e-04  t:2441.1s  ↓4.430e-04
2025-07-19 23:34:47,088 | INFO     | train - Saved best model (epoch 4).
2025-07-19 23:34:47,326 | INFO     | model - Model exported successfully with torch.export.
2025-07-19 23:34:47,326 | ERROR    | train - Model export failed: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 447, in _export_model
    export_model(self.model, example, path, self.cfg)
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 278, in export_model
    test_output = exported_model(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/export/exported_program.py", line 1242, in __call__
    raise RuntimeError(
RuntimeError: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
2025-07-20 15:52:02,184 | INFO     | train - E005  train:1.214e-02  val:2.791e-03  lr:1.00e-04  t:58634.9s  ↓4.836e-04
2025-07-20 15:52:02,219 | INFO     | train - Saved best model (epoch 5).
2025-07-20 15:52:02,532 | INFO     | model - Model exported successfully with torch.export.
2025-07-20 15:52:02,532 | ERROR    | train - Model export failed: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
Traceback (most recent call last):
  File "/Users/imalsky/Desktop/Problemulator/src/train.py", line 447, in _export_model
    export_model(self.model, example, path, self.cfg)
  File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 278, in export_model
    test_output = exported_model(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/export/exported_program.py", line 1242, in __call__
    raise RuntimeError(
RuntimeError: Unable to call ExportedProgram directly. You should use `exported_program.module()` instead.
2025-07-22 14:07:13,623 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-22 14:07:13,623 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-22 14:07:13,623 | INFO     | utils - Generating new dataset splits...
2025-07-22 14:07:13,681 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-22 14:07:13,802 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-22 14:07:13,804 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-22 14:07:13,805 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-22 14:07:13,805 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-22 14:07:13,805 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-22 14:08:02,356 | INFO     | normalizer - Finished statistics calculation in 48.55s.
2025-07-22 14:08:02,516 | INFO     | normalizer - Statistics calculation complete.
2025-07-22 14:08:02,517 | INFO     | preprocess - Normalization metadata computed and saved in 48.71s.
2025-07-22 14:08:02,517 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-22 14:08:02,522 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-22 14:08:50,009 | INFO     | preprocess - Completed train split in 47.49s.
2025-07-22 14:08:50,012 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-22 14:09:00,135 | INFO     | preprocess - Completed val split in 10.13s.
2025-07-22 14:09:00,138 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-22 14:09:09,946 | INFO     | preprocess - Completed test split in 9.81s.
2025-07-22 14:09:09,946 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-22 14:09:09,946 | INFO     | preprocess - Preprocessing completed successfully in 116.14s.
2025-07-22 14:09:10,060 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-22 14:09:10,068 | INFO     | dataset - Memory estimate: 0.27 GB needed, 13.31 GB safely available
2025-07-22 14:09:10,068 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:09:32,663 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-22 14:09:53,099 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-22 14:10:12,181 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-22 14:10:31,096 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-22 14:10:49,880 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-22 14:11:09,589 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-22 14:11:27,411 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-22 14:11:27,412 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-22 14:11:27,412 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-22 14:11:27,420 | INFO     | dataset - Memory estimate: 0.06 GB needed, 12.74 GB safely available
2025-07-22 14:11:27,420 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:11:44,612 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 14:11:54,197 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-22 14:11:54,197 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-22 14:11:54,206 | INFO     | dataset - Memory estimate: 0.06 GB needed, 12.53 GB safely available
2025-07-22 14:11:54,206 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:12:11,093 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 14:12:20,176 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-22 14:12:20,176 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-22 14:12:20,178 | INFO     | train - Disabling torch.compile to reduce overhead
2025-07-22 14:12:20,217 | INFO     | model - PredictionModel created with 4,807,170 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-22 14:12:20,247 | INFO     | model - Model moved to device: mps
2025-07-22 14:12:20,807 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-22 14:12:20,807 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-22 14:12:20,807 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-22 14:12:20,844 | INFO     | train - Training for 100 epochs.
2025-07-22 14:12:36,715 | ERROR    | __main__ - Pipeline error: Tensor for argument input is on cpu but expected on mps
2025-07-22 14:15:38,167 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-22 14:15:38,167 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-22 14:15:38,167 | INFO     | utils - Generating new dataset splits...
2025-07-22 14:15:38,206 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-22 14:15:38,317 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-22 14:15:38,319 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-22 14:15:38,435 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-22 14:15:38,444 | INFO     | dataset - Memory estimate: 0.27 GB needed, 16.54 GB safely available
2025-07-22 14:15:38,444 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:15:55,793 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-22 14:16:13,734 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-22 14:16:30,767 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-22 14:16:47,244 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-22 14:17:03,787 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-22 14:17:21,210 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-22 14:17:38,777 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-22 14:17:38,777 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-22 14:17:38,777 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-22 14:17:38,783 | INFO     | dataset - Memory estimate: 0.06 GB needed, 15.77 GB safely available
2025-07-22 14:17:38,783 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:17:55,226 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 14:18:03,301 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-22 14:18:03,301 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-22 14:18:03,310 | INFO     | dataset - Memory estimate: 0.06 GB needed, 15.96 GB safely available
2025-07-22 14:18:03,310 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 14:18:19,521 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 14:18:27,436 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-22 14:18:27,437 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-22 14:18:27,438 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-22 14:18:27,473 | INFO     | model - PredictionModel created with 4,807,170 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-22 14:18:27,495 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-22 14:18:27,495 | INFO     | model - Model moved to device: mps
2025-07-22 14:18:28,040 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-22 14:18:28,040 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-22 14:18:28,040 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-22 14:18:28,075 | INFO     | train - Training for 100 epochs.
2025-07-22 15:39:56,457 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-22 15:39:56,457 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-22 15:39:56,457 | INFO     | utils - Generating new dataset splits...
2025-07-22 15:39:56,502 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-22 15:39:56,612 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-22 15:39:56,615 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-22 15:39:56,726 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-22 15:39:56,735 | INFO     | dataset - Memory estimate: 0.27 GB needed, 11.07 GB safely available
2025-07-22 15:39:56,735 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 15:40:18,235 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-22 15:40:42,395 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-22 15:41:04,232 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-22 15:41:30,955 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-22 15:41:51,054 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-22 15:42:13,306 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-22 15:42:35,224 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-22 15:42:35,226 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-22 15:42:35,226 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-22 15:42:35,235 | INFO     | dataset - Memory estimate: 0.06 GB needed, 11.44 GB safely available
2025-07-22 15:42:35,235 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 15:42:53,285 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 15:43:02,339 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-22 15:43:02,339 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-22 15:43:02,345 | INFO     | dataset - Memory estimate: 0.06 GB needed, 11.19 GB safely available
2025-07-22 15:43:02,345 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-22 15:43:21,265 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-22 15:43:30,180 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-22 15:43:30,180 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-22 15:43:30,182 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-22 15:43:30,219 | INFO     | model - PredictionModel created with 4,807,170 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-22 15:43:30,249 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-22 15:43:30,249 | INFO     | model - Model moved to device: mps
2025-07-22 15:43:30,853 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-22 15:43:30,853 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-22 15:43:30,853 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-22 15:43:30,892 | INFO     | train - Training for 100 epochs.
2025-07-22 16:04:09,472 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-22 16:04:09,472 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-22 16:04:09,472 | INFO     | utils - Generating new dataset splits...
2025-07-22 16:04:09,514 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-22 16:04:09,622 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-22 16:04:09,626 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-22 16:04:09,626 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-22 16:04:09,626 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-22 16:04:09,626 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-23 10:05:25,774 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 10:05:25,774 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 10:05:25,774 | INFO     | utils - Generating new dataset splits...
2025-07-23 10:05:25,823 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 10:05:25,934 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 10:05:25,937 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-23 10:05:25,937 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-23 10:05:25,937 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-23 10:05:25,937 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-23 10:06:14,108 | INFO     | normalizer - Finished statistics calculation in 48.17s.
2025-07-23 10:06:14,248 | INFO     | normalizer - Statistics calculation complete.
2025-07-23 10:06:14,249 | INFO     | preprocess - Normalization metadata computed and saved in 48.31s.
2025-07-23 10:06:14,249 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-23 10:06:14,253 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-23 10:07:02,848 | INFO     | preprocess - Completed train split in 48.60s.
2025-07-23 10:07:02,851 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-23 10:07:12,856 | INFO     | preprocess - Completed val split in 10.01s.
2025-07-23 10:07:12,858 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-23 10:07:22,735 | INFO     | preprocess - Completed test split in 9.88s.
2025-07-23 10:07:22,735 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-23 10:07:22,735 | INFO     | preprocess - Preprocessing completed successfully in 116.80s.
2025-07-23 10:07:22,853 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 10:07:22,860 | INFO     | dataset - Memory estimate: 0.27 GB needed, 14.15 GB safely available
2025-07-23 10:07:22,860 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 10:07:41,942 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 10:07:59,412 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 10:08:14,943 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-23 10:08:30,401 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-23 10:08:47,791 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-23 10:09:04,560 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-23 10:09:20,953 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-23 10:09:20,954 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-23 10:09:20,954 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 10:09:20,963 | INFO     | dataset - Memory estimate: 0.06 GB needed, 13.41 GB safely available
2025-07-23 10:09:20,963 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 10:09:38,751 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 10:09:47,489 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-23 10:09:47,489 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 10:09:47,495 | INFO     | dataset - Memory estimate: 0.06 GB needed, 13.53 GB safely available
2025-07-23 10:09:47,495 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 10:10:03,763 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 10:10:12,256 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-23 10:10:12,256 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-23 10:10:12,258 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 10:10:12,300 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 10:10:12,320 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 10:10:12,320 | INFO     | model - Model moved to device: mps
2025-07-23 10:10:13,033 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 10:10:13,034 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 10:10:13,034 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 10:10:13,075 | INFO     | train - Training for 100 epochs.
2025-07-23 10:18:55,617 | INFO     | train - E001  train:3.493e+10  val:1.330e+10  lr:1.00e-04  t:522.5s  ↓inf
2025-07-23 10:18:55,665 | INFO     | train - Saved best model (epoch 1).
2025-07-23 10:18:55,696 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 10:18:55,745 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 10:18:55,763 | INFO     | model - Model moved to device: mps
2025-07-23 10:18:56,048 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 11:00:37,973 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 11:00:37,973 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 11:00:37,973 | INFO     | utils - Generating new dataset splits...
2025-07-23 11:00:38,019 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 11:00:38,175 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 11:00:38,179 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 11:00:38,309 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 11:00:38,319 | INFO     | dataset - Memory estimate: 0.27 GB needed, 8.36 GB safely available
2025-07-23 11:00:38,320 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 11:00:56,752 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 11:01:15,563 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 11:01:35,182 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-23 11:01:53,533 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-23 11:02:13,944 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-23 11:02:35,188 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-23 11:03:01,338 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-23 11:03:01,339 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-23 11:03:01,339 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 11:03:01,356 | INFO     | dataset - Memory estimate: 0.06 GB needed, 7.65 GB safely available
2025-07-23 11:03:01,356 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 11:03:23,965 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 11:03:33,800 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-23 11:03:33,800 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 11:03:33,809 | INFO     | dataset - Memory estimate: 0.06 GB needed, 7.59 GB safely available
2025-07-23 11:03:33,809 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 11:03:52,009 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 11:04:01,048 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-23 11:04:01,048 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-23 11:04:01,051 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 11:04:01,101 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 11:04:01,127 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 11:04:01,127 | INFO     | model - Model moved to device: mps
2025-07-23 11:04:01,791 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 11:04:01,791 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 11:04:01,791 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 11:04:01,825 | INFO     | train - Training for 100 epochs.
2025-07-23 12:41:27,414 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 12:41:27,414 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 12:41:27,414 | INFO     | utils - Generating new dataset splits...
2025-07-23 12:41:27,458 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 12:41:27,569 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 12:41:27,573 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 12:41:27,692 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 12:41:27,702 | INFO     | dataset - Memory estimate: 0.27 GB needed, 14.50 GB safely available
2025-07-23 12:41:27,702 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:41:46,041 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 12:42:03,749 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 12:42:20,560 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-23 12:42:37,504 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-23 12:42:55,032 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-23 12:43:12,138 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-23 12:43:28,956 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-23 12:43:28,956 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-23 12:43:28,956 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 12:43:28,968 | INFO     | dataset - Memory estimate: 0.06 GB needed, 14.30 GB safely available
2025-07-23 12:43:28,968 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:43:45,469 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 12:43:54,384 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-23 12:43:54,384 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 12:43:54,391 | INFO     | dataset - Memory estimate: 0.06 GB needed, 14.10 GB safely available
2025-07-23 12:43:54,391 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:44:11,762 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 12:44:20,815 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-23 12:44:20,815 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-23 12:44:20,817 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 12:44:20,864 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 12:44:20,899 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 12:44:20,899 | INFO     | model - Model moved to device: mps
2025-07-23 12:44:21,578 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 12:44:21,578 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 12:44:21,578 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 12:44:21,616 | INFO     | train - Training for 100 epochs.
2025-07-23 12:52:43,027 | INFO     | train - E001  train:3.493e+10  val:1.330e+10  lr:1.00e-04  t:501.4s  ↓inf
2025-07-23 12:52:43,064 | INFO     | train - Saved best model (epoch 1).
2025-07-23 12:52:43,088 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 12:52:43,135 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 12:52:43,158 | INFO     | model - Model moved to device: mps
2025-07-23 12:52:43,519 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 12:52:43,519 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 12:52:44,062 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 12:52:45,232 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 12:53:28,150 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 12:53:28,151 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 12:53:28,151 | INFO     | utils - Generating new dataset splits...
2025-07-23 12:53:28,201 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 12:53:28,322 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 12:53:28,329 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 12:53:28,467 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 12:53:28,496 | INFO     | dataset - Memory estimate: 0.27 GB needed, 9.23 GB safely available
2025-07-23 12:53:28,496 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:53:48,260 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 12:54:06,446 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 12:54:25,328 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-23 12:55:09,494 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 12:55:09,494 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 12:55:09,494 | INFO     | utils - Generating new dataset splits...
2025-07-23 12:55:09,536 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 12:55:09,649 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 12:55:09,653 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 12:55:09,781 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 12:55:09,788 | INFO     | dataset - Memory estimate: 0.27 GB needed, 7.91 GB safely available
2025-07-23 12:55:09,788 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:55:27,293 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 12:55:46,437 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 12:55:57,432 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 12:55:57,432 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 12:55:57,432 | INFO     | utils - Generating new dataset splits...
2025-07-23 12:55:57,482 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 12:55:57,603 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 12:55:57,605 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-23 12:55:57,605 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-23 12:55:57,605 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-23 12:55:57,605 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-23 12:56:45,944 | INFO     | normalizer - Finished statistics calculation in 48.34s.
2025-07-23 12:56:46,095 | INFO     | normalizer - Statistics calculation complete.
2025-07-23 12:56:46,097 | INFO     | preprocess - Normalization metadata computed and saved in 48.49s.
2025-07-23 12:56:46,097 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-23 12:56:46,101 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-23 12:57:35,176 | INFO     | preprocess - Completed train split in 49.08s.
2025-07-23 12:57:35,183 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-23 12:57:44,974 | INFO     | preprocess - Completed val split in 9.80s.
2025-07-23 12:57:44,979 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-23 12:57:54,842 | INFO     | preprocess - Completed test split in 9.87s.
2025-07-23 12:57:54,843 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-23 12:57:54,846 | INFO     | preprocess - Preprocessing completed successfully in 117.24s.
2025-07-23 12:57:54,959 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 12:57:54,964 | INFO     | utils - Global random seed set to 42.
2025-07-23 12:57:54,967 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 12:57:54,978 | INFO     | dataset - Memory estimate: 0.03 GB needed, 6.22 GB safely available
2025-07-23 12:57:54,978 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:58:09,656 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 12:58:09,657 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 12:58:09,664 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.30 GB safely available
2025-07-23 12:58:09,664 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:58:13,093 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 12:58:13,093 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 12:58:13,098 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.20 GB safely available
2025-07-23 12:58:13,098 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 12:58:16,122 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 12:58:16,122 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 12:58:16,126 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 12:58:16,169 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 12:58:16,193 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 12:58:16,193 | INFO     | model - Model moved to device: mps
2025-07-23 12:58:16,792 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 12:58:16,792 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 12:58:16,792 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 12:58:16,829 | INFO     | train - Training for 100 epochs.
2025-07-23 12:59:34,185 | INFO     | train - E001  train:3.511e+09  val:1.160e+12  lr:1.00e-04  t:77.4s  ↓inf
2025-07-23 12:59:34,253 | INFO     | train - Saved best model (epoch 1).
2025-07-23 12:59:34,265 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 12:59:34,309 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 12:59:34,329 | INFO     | model - Model moved to device: mps
2025-07-23 12:59:34,663 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 12:59:34,663 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 12:59:35,256 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 12:59:36,885 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 12:59:36,886 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:14:10,710 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 13:14:10,711 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 13:14:10,711 | INFO     | utils - Generating new dataset splits...
2025-07-23 13:14:10,755 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 13:14:10,871 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 13:14:10,874 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 13:14:10,988 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 13:14:10,991 | INFO     | utils - Global random seed set to 42.
2025-07-23 13:14:10,994 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 13:14:11,000 | INFO     | dataset - Memory estimate: 0.03 GB needed, 8.84 GB safely available
2025-07-23 13:14:11,000 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:14:24,519 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 13:14:24,519 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 13:14:24,526 | INFO     | dataset - Memory estimate: 0.01 GB needed, 8.46 GB safely available
2025-07-23 13:14:24,526 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:14:27,331 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 13:14:27,331 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 13:14:27,338 | INFO     | dataset - Memory estimate: 0.01 GB needed, 8.59 GB safely available
2025-07-23 13:14:27,338 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:14:30,145 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 13:14:30,145 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 13:14:30,147 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 13:14:30,190 | INFO     | model - PredictionModel created with 4,813,314 trainable parameters. Architecture: d_model=256, nhead=8, layers=6
2025-07-23 13:14:30,216 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 13:14:30,216 | INFO     | model - Model moved to device: mps
2025-07-23 13:14:30,777 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 13:14:30,777 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 13:14:30,777 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 13:14:30,813 | INFO     | train - Training for 100 epochs.
2025-07-23 13:15:39,821 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 13:15:39,821 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 13:15:39,821 | INFO     | utils - Generating new dataset splits...
2025-07-23 13:15:39,864 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 13:15:39,980 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 13:15:39,982 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-23 13:15:39,982 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-23 13:15:39,982 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-23 13:15:39,982 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-23 13:16:29,194 | INFO     | normalizer - Finished statistics calculation in 49.21s.
2025-07-23 13:16:29,351 | INFO     | normalizer - Statistics calculation complete.
2025-07-23 13:16:29,352 | INFO     | preprocess - Normalization metadata computed and saved in 49.37s.
2025-07-23 13:16:29,352 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-23 13:16:29,357 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-23 13:17:18,425 | INFO     | preprocess - Completed train split in 49.07s.
2025-07-23 13:17:18,431 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-23 13:17:28,449 | INFO     | preprocess - Completed val split in 10.02s.
2025-07-23 13:17:28,456 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-23 13:17:38,369 | INFO     | preprocess - Completed test split in 9.92s.
2025-07-23 13:17:38,369 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-23 13:17:38,369 | INFO     | preprocess - Preprocessing completed successfully in 118.39s.
2025-07-23 13:17:38,483 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 13:17:38,486 | INFO     | utils - Global random seed set to 42.
2025-07-23 13:17:38,489 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 13:17:38,498 | INFO     | dataset - Memory estimate: 0.03 GB needed, 8.74 GB safely available
2025-07-23 13:17:38,498 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:17:52,303 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 13:17:52,303 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 13:17:52,311 | INFO     | dataset - Memory estimate: 0.01 GB needed, 8.72 GB safely available
2025-07-23 13:17:52,311 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:17:55,125 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 13:17:55,126 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 13:17:55,131 | INFO     | dataset - Memory estimate: 0.01 GB needed, 8.73 GB safely available
2025-07-23 13:17:55,132 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:17:58,161 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 13:17:58,162 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 13:17:58,163 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 13:17:58,171 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:17:58,187 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 13:17:58,187 | INFO     | model - Model moved to device: mps
2025-07-23 13:17:58,758 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 13:17:58,758 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 13:17:58,758 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 13:17:58,798 | INFO     | train - Training for 100 epochs.
2025-07-23 13:18:40,852 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:42.1s  ↓inf
2025-07-23 13:18:40,868 | INFO     | train - Saved best model (epoch 1).
2025-07-23 13:18:40,910 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:18:40,918 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:18:40,926 | INFO     | model - Model moved to device: mps
2025-07-23 13:18:41,522 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:18:41,522 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:18:41,858 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:18:42,738 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 13:18:42,738 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:18:53,792 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:11.1s  ↓1.283e+00
2025-07-23 13:18:53,804 | INFO     | train - Saved best model (epoch 2).
2025-07-23 13:18:53,810 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:18:53,816 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:18:53,823 | INFO     | model - Model moved to device: mps
2025-07-23 13:18:53,891 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:18:53,892 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:18:54,178 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:18:54,520 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_2_exported.onnx
2025-07-23 13:18:54,521 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:19:05,879 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:11.4s  ↓2.588e-01
2025-07-23 13:19:05,894 | INFO     | train - Saved best model (epoch 3).
2025-07-23 13:19:05,905 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:19:05,912 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:19:05,922 | INFO     | model - Model moved to device: mps
2025-07-23 13:19:05,997 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:19:05,997 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:19:06,268 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:19:06,599 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_3_exported.onnx
2025-07-23 13:19:06,599 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:19:17,811 | INFO     | train - E004  train:3.023e-01  val:2.616e-01  lr:1.00e-04  t:11.2s  ↓1.086e-01
2025-07-23 13:19:17,829 | INFO     | train - Saved best model (epoch 4).
2025-07-23 13:19:17,835 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:19:17,845 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:19:17,857 | INFO     | model - Model moved to device: mps
2025-07-23 13:19:17,940 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:19:17,940 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:19:18,288 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:19:18,664 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_4_exported.onnx
2025-07-23 13:19:18,664 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:19:29,606 | INFO     | train - E005  train:2.307e-01  val:2.301e-01  lr:1.00e-04  t:10.9s  ↓3.154e-02
2025-07-23 13:19:29,619 | INFO     | train - Saved best model (epoch 5).
2025-07-23 13:19:29,634 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:19:29,640 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:19:29,651 | INFO     | model - Model moved to device: mps
2025-07-23 13:19:29,735 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:19:29,735 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:19:30,022 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:19:30,353 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_5_exported.onnx
2025-07-23 13:19:30,354 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 13:33:19,833 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 13:33:19,833 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 13:33:19,833 | INFO     | utils - Generating new dataset splits...
2025-07-23 13:33:19,874 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 13:33:19,986 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 13:33:19,989 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 13:33:20,099 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 13:33:20,103 | INFO     | utils - Global random seed set to 42.
2025-07-23 13:33:20,105 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 13:33:20,115 | INFO     | dataset - Memory estimate: 0.03 GB needed, 17.65 GB safely available
2025-07-23 13:33:20,116 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:33:34,406 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 13:33:34,406 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 13:33:34,415 | INFO     | dataset - Memory estimate: 0.01 GB needed, 17.76 GB safely available
2025-07-23 13:33:34,415 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:33:37,223 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 13:33:37,223 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 13:33:37,231 | INFO     | dataset - Memory estimate: 0.01 GB needed, 17.70 GB safely available
2025-07-23 13:33:37,231 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:33:40,049 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 13:33:40,049 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 13:33:40,051 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 13:33:40,057 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:33:40,078 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 13:33:40,078 | INFO     | model - Model moved to device: mps
2025-07-23 13:33:40,604 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 13:33:40,604 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 13:33:40,604 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 13:33:40,638 | INFO     | train - Training for 100 epochs.
2025-07-23 13:36:12,870 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 13:36:12,870 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 13:36:12,870 | INFO     | utils - Generating new dataset splits...
2025-07-23 13:36:12,923 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 13:36:13,034 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 13:36:13,035 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 13:36:13,148 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 13:36:13,149 | INFO     | utils - Global random seed set to 42.
2025-07-23 13:36:13,151 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 13:36:13,162 | INFO     | dataset - Memory estimate: 0.03 GB needed, 12.95 GB safely available
2025-07-23 13:36:13,162 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:36:28,588 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 13:36:28,589 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 13:36:28,599 | INFO     | dataset - Memory estimate: 0.01 GB needed, 12.95 GB safely available
2025-07-23 13:36:28,599 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:36:31,923 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 13:36:31,923 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 13:36:31,932 | INFO     | dataset - Memory estimate: 0.01 GB needed, 12.94 GB safely available
2025-07-23 13:36:31,932 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:36:34,929 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 13:36:34,929 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 13:36:34,930 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 13:36:34,939 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:36:34,953 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 13:36:34,953 | INFO     | model - Model moved to device: mps
2025-07-23 13:36:35,805 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 13:36:35,805 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 13:36:35,805 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 13:36:35,842 | INFO     | train - Training for 100 epochs.
2025-07-23 13:37:12,389 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:36.5s  ↓inf
2025-07-23 13:37:12,404 | INFO     | train - Saved best model (epoch 1).
2025-07-23 13:37:12,411 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:37:12,417 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:37:12,425 | INFO     | model - Model moved to device: mps
2025-07-23 13:37:12,824 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:37:12,824 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:37:13,167 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:37:13,818 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:37:24,640 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:10.8s  ↓1.283e+00
2025-07-23 13:37:24,651 | INFO     | train - Saved best model (epoch 2).
2025-07-23 13:37:24,657 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:37:24,664 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:37:24,672 | INFO     | model - Model moved to device: mps
2025-07-23 13:37:24,742 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:37:24,742 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:37:24,987 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:37:25,404 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:37:35,843 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:10.4s  ↓2.588e-01
2025-07-23 13:37:35,855 | INFO     | train - Saved best model (epoch 3).
2025-07-23 13:37:35,861 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:37:35,866 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:37:35,876 | INFO     | model - Model moved to device: mps
2025-07-23 13:37:35,941 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:37:35,941 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:37:36,219 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:37:36,621 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:37:47,120 | INFO     | train - E004  train:3.023e-01  val:2.616e-01  lr:1.00e-04  t:10.5s  ↓1.086e-01
2025-07-23 13:37:47,132 | INFO     | train - Saved best model (epoch 4).
2025-07-23 13:37:47,138 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:37:47,144 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:37:47,153 | INFO     | model - Model moved to device: mps
2025-07-23 13:37:47,218 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:37:47,218 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:37:47,471 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:37:47,880 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:37:58,653 | INFO     | train - E005  train:2.307e-01  val:2.301e-01  lr:1.00e-04  t:10.8s  ↓3.154e-02
2025-07-23 13:37:58,665 | INFO     | train - Saved best model (epoch 5).
2025-07-23 13:37:58,675 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:37:58,681 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:37:58,689 | INFO     | model - Model moved to device: mps
2025-07-23 13:37:58,765 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:37:58,765 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:37:59,097 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:37:59,562 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:38:10,261 | INFO     | train - E006  train:1.888e-01  val:1.768e-01  lr:1.00e-04  t:10.7s  ↓5.334e-02
2025-07-23 13:38:10,274 | INFO     | train - Saved best model (epoch 6).
2025-07-23 13:38:10,280 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:38:10,286 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:38:10,295 | INFO     | model - Model moved to device: mps
2025-07-23 13:38:10,360 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:38:10,361 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:38:10,653 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:38:11,060 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:38:21,514 | INFO     | train - E007  train:1.585e-01  val:1.587e-01  lr:1.00e-04  t:10.5s  ↓1.805e-02
2025-07-23 13:38:21,526 | INFO     | train - Saved best model (epoch 7).
2025-07-23 13:38:21,531 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:38:21,537 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:38:21,546 | INFO     | model - Model moved to device: mps
2025-07-23 13:38:21,611 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:38:21,611 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:38:21,847 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:38:22,240 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:38:32,997 | INFO     | train - E008  train:1.433e-01  val:1.440e-01  lr:1.00e-04  t:10.8s  ↓1.476e-02
2025-07-23 13:38:33,008 | INFO     | train - Saved best model (epoch 8).
2025-07-23 13:38:33,014 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:38:33,020 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:38:33,028 | INFO     | model - Model moved to device: mps
2025-07-23 13:38:33,098 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:38:33,098 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:38:33,407 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:38:33,809 | ERROR    | model - ONNX export failed: Module onnx is not installed!
2025-07-23 13:39:55,961 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 13:39:55,961 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 13:39:55,961 | INFO     | utils - Generating new dataset splits...
2025-07-23 13:39:56,021 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 13:39:56,150 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 13:39:56,152 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 13:39:56,273 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 13:39:56,274 | INFO     | utils - Global random seed set to 42.
2025-07-23 13:39:56,276 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 13:39:56,284 | INFO     | dataset - Memory estimate: 0.03 GB needed, 10.68 GB safely available
2025-07-23 13:39:56,284 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:40:11,077 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 13:40:11,077 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 13:40:11,084 | INFO     | dataset - Memory estimate: 0.01 GB needed, 10.88 GB safely available
2025-07-23 13:40:11,084 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:40:14,415 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 13:40:14,415 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 13:40:14,420 | INFO     | dataset - Memory estimate: 0.01 GB needed, 10.80 GB safely available
2025-07-23 13:40:14,420 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 13:40:17,439 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 13:40:17,439 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 13:40:17,439 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 13:40:17,446 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:40:17,465 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 13:40:17,465 | INFO     | model - Model moved to device: mps
2025-07-23 13:40:18,040 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 13:40:18,040 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 13:40:18,040 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 13:40:18,080 | INFO     | train - Training for 100 epochs.
2025-07-23 13:40:55,480 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:37.4s  ↓inf
2025-07-23 13:40:55,493 | INFO     | train - Saved best model (epoch 1).
2025-07-23 13:40:55,502 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 13:40:55,510 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 13:40:55,519 | INFO     | model - Model moved to device: mps
2025-07-23 13:40:56,077 | ERROR    | model - torch.export failed: Constraints violated (batch)! For more information, run with TORCH_LOGS="+dynamic".
  - Not all values of batch = L['sequence'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['global_features'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).
  - Not all values of batch = L['sequence_mask'].size()[0] in the specified range are valid because batch was inferred to be a constant (1).

Suggested fixes:
  batch = 1
2025-07-23 13:40:56,077 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 13:40:56,430 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 13:40:57,686 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 13:40:57,686 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:02:22,066 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:02:22,066 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:02:22,066 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:02:22,110 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:02:22,225 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:02:22,227 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:02:22,342 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:02:22,346 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:02:22,349 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:02:22,360 | INFO     | dataset - Memory estimate: 0.03 GB needed, 7.45 GB safely available
2025-07-23 14:02:22,360 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:02:37,072 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:02:37,072 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:02:37,079 | INFO     | dataset - Memory estimate: 0.01 GB needed, 7.38 GB safely available
2025-07-23 14:02:37,079 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:02:39,830 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:02:39,830 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:02:39,836 | INFO     | dataset - Memory estimate: 0.01 GB needed, 7.46 GB safely available
2025-07-23 14:02:39,836 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:02:42,587 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:02:42,587 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:02:42,588 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:02:42,593 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:02:42,612 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:02:42,612 | INFO     | model - Model moved to device: mps
2025-07-23 14:02:43,227 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:02:43,227 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:02:43,227 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:02:43,263 | INFO     | train - Training for 100 epochs.
2025-07-23 14:03:19,394 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:36.1s  ↓inf
2025-07-23 14:03:19,446 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:03:19,456 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:03:19,463 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:03:19,471 | INFO     | model - Model moved to device: mps
2025-07-23 14:03:20,048 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._scaled_dot_product_attention_math_for_mps.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:03:20,048 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:03:20,432 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:03:21,258 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 14:03:21,258 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:03:31,837 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:10.6s  ↓1.283e+00
2025-07-23 14:03:31,848 | INFO     | train - Saved best model (epoch 2).
2025-07-23 14:03:31,854 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:03:31,860 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:03:31,868 | INFO     | model - Model moved to device: mps
2025-07-23 14:03:31,945 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._scaled_dot_product_attention_math_for_mps.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:03:31,945 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:03:32,218 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:03:32,593 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_2_exported.onnx
2025-07-23 14:03:32,594 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:03:43,055 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:10.5s  ↓2.588e-01
2025-07-23 14:03:43,068 | INFO     | train - Saved best model (epoch 3).
2025-07-23 14:03:43,073 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:03:43,079 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:03:43,088 | INFO     | model - Model moved to device: mps
2025-07-23 14:03:43,158 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._scaled_dot_product_attention_math_for_mps.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:03:43,158 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:03:43,411 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:03:43,749 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_3_exported.onnx
2025-07-23 14:03:43,749 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:09:17,162 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:09:17,162 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:09:17,162 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:09:17,203 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:09:17,319 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:09:17,323 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:09:17,438 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:09:17,442 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:09:17,444 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:09:17,452 | INFO     | dataset - Memory estimate: 0.03 GB needed, 6.69 GB safely available
2025-07-23 14:09:17,452 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:09:30,474 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:09:30,474 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:09:30,480 | INFO     | dataset - Memory estimate: 0.01 GB needed, 7.02 GB safely available
2025-07-23 14:09:30,480 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:09:33,059 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:09:33,059 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:09:33,066 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.94 GB safely available
2025-07-23 14:09:33,066 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:09:35,641 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:09:35,641 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:09:35,643 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:09:35,649 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:09:35,731 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:09:35,731 | INFO     | model - Model moved to device: mps
2025-07-23 14:09:36,331 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:09:36,331 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:09:36,331 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:09:36,367 | INFO     | train - Training for 100 epochs.
2025-07-23 14:10:13,431 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:37.1s  ↓inf
2025-07-23 14:10:13,447 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:10:13,466 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:10:13,474 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:10:13,484 | INFO     | model - Model moved to device: mps
2025-07-23 14:10:13,752 | ERROR    | model - torch.export failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(s0, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:10:13,752 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:10:13,759 | ERROR    | model - Fallback export also failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(2, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:10:24,314 | INFO     | train - E002  train:9.946e-01  val:5.265e-01  lr:1.00e-04  t:10.6s  ↓1.385e+00
2025-07-23 14:10:24,325 | INFO     | train - Saved best model (epoch 2).
2025-07-23 14:10:24,331 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:10:24,337 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:10:24,345 | INFO     | model - Model moved to device: mps
2025-07-23 14:10:24,364 | ERROR    | model - torch.export failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(s0, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:10:24,364 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:10:24,372 | ERROR    | model - Fallback export also failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(2, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:10:34,727 | INFO     | train - E003  train:4.040e-01  val:3.154e-01  lr:1.00e-04  t:10.4s  ↓2.112e-01
2025-07-23 14:10:34,741 | INFO     | train - Saved best model (epoch 3).
2025-07-23 14:10:34,752 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:10:34,760 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:10:34,773 | INFO     | model - Model moved to device: mps
2025-07-23 14:10:34,795 | ERROR    | model - torch.export failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(s0, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:10:34,795 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:10:34,803 | ERROR    | model - Fallback export also failed: Dynamo failed to run FX node with fake tensors: call_module L__self___input_proj_0(*(FakeTensor(..., device='mps:0', size=(2, 256, 2)),), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.mm.default, found two different devices mps:0, cpu')

from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 180, in forward
    x = self.input_proj(sequence)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:12:59,331 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:12:59,331 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:12:59,331 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:12:59,375 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:12:59,490 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:12:59,491 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:12:59,601 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:12:59,605 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:12:59,607 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:12:59,614 | INFO     | dataset - Memory estimate: 0.03 GB needed, 6.37 GB safely available
2025-07-23 14:12:59,614 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:13:13,121 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:13:13,121 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:13:13,127 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.33 GB safely available
2025-07-23 14:13:13,127 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:13:15,808 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:13:15,808 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:13:15,815 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.31 GB safely available
2025-07-23 14:13:15,815 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:13:18,496 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:13:18,497 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:13:18,498 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:13:18,504 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:13:18,529 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:13:18,529 | INFO     | model - Model moved to device: mps
2025-07-23 14:13:19,089 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:13:19,089 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:13:19,089 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:13:19,125 | INFO     | train - Training for 100 epochs.
2025-07-23 14:13:56,863 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:37.7s  ↓inf
2025-07-23 14:13:56,878 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:13:56,887 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:13:56,900 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:13:56,922 | INFO     | model - Model moved to device: mps
2025-07-23 14:13:57,129 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:13:57,129 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:13:57,509 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:13:57,903 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 14:13:57,903 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:14:09,005 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:11.1s  ↓1.283e+00
2025-07-23 14:14:09,017 | INFO     | train - Saved best model (epoch 2).
2025-07-23 14:14:09,025 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:14:09,031 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:14:09,040 | INFO     | model - Model moved to device: mps
2025-07-23 14:14:09,093 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:14:09,093 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:14:09,322 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:14:09,551 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_2_exported.onnx
2025-07-23 14:14:09,551 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:14:20,609 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:11.0s  ↓2.588e-01
2025-07-23 14:14:20,623 | INFO     | train - Saved best model (epoch 3).
2025-07-23 14:14:20,629 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:14:20,636 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:14:20,645 | INFO     | model - Model moved to device: mps
2025-07-23 14:14:20,699 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:14:20,700 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:14:20,972 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:14:21,252 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_3_exported.onnx
2025-07-23 14:14:21,253 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:14:31,795 | INFO     | train - E004  train:3.023e-01  val:2.620e-01  lr:1.00e-04  t:10.5s  ↓1.082e-01
2025-07-23 14:14:31,807 | INFO     | train - Saved best model (epoch 4).
2025-07-23 14:14:31,813 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:14:31,819 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:14:31,826 | INFO     | model - Model moved to device: mps
2025-07-23 14:14:31,900 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:14:31,901 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:14:32,246 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:14:32,497 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_4_exported.onnx
2025-07-23 14:14:32,497 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:14:44,548 | INFO     | train - E005  train:2.266e-01  val:2.477e-01  lr:1.00e-04  t:12.0s  ↓1.429e-02
2025-07-23 14:14:44,559 | INFO     | train - Saved best model (epoch 5).
2025-07-23 14:14:44,564 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:14:44,570 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:14:44,578 | INFO     | model - Model moved to device: mps
2025-07-23 14:14:44,633 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:14:44,633 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:14:44,964 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:14:45,195 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_5_exported.onnx
2025-07-23 14:14:45,195 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:14:56,142 | INFO     | train - E006  train:1.923e-01  val:1.699e-01  lr:1.00e-04  t:10.9s  ↓7.775e-02
2025-07-23 14:14:56,154 | INFO     | train - Saved best model (epoch 6).
2025-07-23 14:14:56,162 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:14:56,168 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:14:56,176 | INFO     | model - Model moved to device: mps
2025-07-23 14:14:56,229 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:14:56,229 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:14:56,514 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:14:56,734 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_6_exported.onnx
2025-07-23 14:14:56,734 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:15:07,647 | INFO     | train - E007  train:1.740e-01  val:1.627e-01  lr:1.00e-04  t:10.9s  ↓7.240e-03
2025-07-23 14:15:07,659 | INFO     | train - Saved best model (epoch 7).
2025-07-23 14:15:07,670 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:15:07,676 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:15:07,685 | INFO     | model - Model moved to device: mps
2025-07-23 14:15:07,739 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:15:07,740 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:15:07,972 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:15:08,210 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_7_exported.onnx
2025-07-23 14:15:08,210 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:15:19,270 | INFO     | train - E008  train:1.495e-01  val:1.457e-01  lr:1.00e-04  t:11.0s  ↓1.702e-02
2025-07-23 14:15:19,284 | INFO     | train - Saved best model (epoch 8).
2025-07-23 14:15:19,298 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:15:19,305 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:15:19,315 | INFO     | model - Model moved to device: mps
2025-07-23 14:15:19,372 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:15:19,372 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:15:19,658 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:15:19,881 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_8_exported.onnx
2025-07-23 14:15:19,881 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:15:30,787 | INFO     | train - E009  train:1.288e-01  val:1.327e-01  lr:1.00e-04  t:10.9s  ↓1.302e-02
2025-07-23 14:15:30,800 | INFO     | train - Saved best model (epoch 9).
2025-07-23 14:15:30,805 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:15:30,811 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:15:30,819 | INFO     | model - Model moved to device: mps
2025-07-23 14:15:30,874 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:15:30,874 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:15:31,155 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:15:31,430 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_9_exported.onnx
2025-07-23 14:15:31,431 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:15:42,197 | INFO     | train - E010  train:1.197e-01  val:1.248e-01  lr:1.00e-04  t:10.8s  ↓7.808e-03
2025-07-23 14:15:42,209 | INFO     | train - Saved best model (epoch 10).
2025-07-23 14:15:42,214 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:15:42,219 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:15:42,228 | INFO     | model - Model moved to device: mps
2025-07-23 14:15:42,281 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:15:42,281 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:15:42,509 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:15:42,740 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_10_exported.onnx
2025-07-23 14:15:42,740 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:15:53,211 | INFO     | train - E011  train:1.101e-01  val:1.078e-01  lr:1.00e-04  t:10.5s  ↓1.705e-02
2025-07-23 14:15:53,225 | INFO     | train - Saved best model (epoch 11).
2025-07-23 14:15:53,230 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:15:53,236 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:15:53,245 | INFO     | model - Model moved to device: mps
2025-07-23 14:15:53,300 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:15:53,300 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:15:53,617 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:15:53,838 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_11_exported.onnx
2025-07-23 14:15:53,839 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:16:04,206 | INFO     | train - E012  train:1.037e-01  val:1.303e-01  lr:1.00e-04  t:10.4s
2025-07-23 14:16:14,558 | INFO     | train - E013  train:9.781e-02  val:1.023e-01  lr:1.00e-04  t:10.4s  ↓5.547e-03
2025-07-23 14:16:14,572 | INFO     | train - Saved best model (epoch 13).
2025-07-23 14:16:14,577 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:16:14,583 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:16:14,594 | INFO     | model - Model moved to device: mps
2025-07-23 14:16:14,681 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:16:14,681 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:16:14,907 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:16:15,133 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_13_exported.onnx
2025-07-23 14:16:15,133 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:16:25,507 | INFO     | train - E014  train:9.062e-02  val:9.664e-02  lr:1.00e-04  t:10.4s  ↓5.611e-03
2025-07-23 14:16:25,519 | INFO     | train - Saved best model (epoch 14).
2025-07-23 14:16:25,524 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:16:25,531 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:16:25,540 | INFO     | model - Model moved to device: mps
2025-07-23 14:16:25,595 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:16:25,595 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:16:25,877 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:16:26,102 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_14_exported.onnx
2025-07-23 14:16:26,102 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:16:36,470 | INFO     | train - E015  train:8.574e-02  val:9.138e-02  lr:1.00e-04  t:10.4s  ↓5.260e-03
2025-07-23 14:16:36,483 | INFO     | train - Saved best model (epoch 15).
2025-07-23 14:16:36,488 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:16:36,495 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:16:36,504 | INFO     | model - Model moved to device: mps
2025-07-23 14:16:36,560 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:16:36,560 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:16:36,786 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:16:37,009 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_15_exported.onnx
2025-07-23 14:16:37,010 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:16:47,510 | INFO     | train - E016  train:8.279e-02  val:7.981e-02  lr:1.00e-04  t:10.5s  ↓1.157e-02
2025-07-23 14:16:47,524 | INFO     | train - Saved best model (epoch 16).
2025-07-23 14:16:47,529 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:16:47,536 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:16:47,545 | INFO     | model - Model moved to device: mps
2025-07-23 14:16:47,598 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:16:47,599 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:16:47,875 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:16:48,102 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_16_exported.onnx
2025-07-23 14:16:48,103 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:16:58,467 | INFO     | train - E017  train:9.738e-02  val:9.085e-02  lr:1.00e-04  t:10.4s
2025-07-23 14:17:08,864 | INFO     | train - E018  train:8.006e-02  val:8.122e-02  lr:1.00e-04  t:10.4s
2025-07-23 14:17:19,661 | INFO     | train - E019  train:7.546e-02  val:8.657e-02  lr:1.00e-04  t:10.8s
2025-07-23 14:17:30,022 | INFO     | train - E020  train:7.190e-02  val:7.272e-02  lr:1.00e-04  t:10.4s  ↓7.093e-03
2025-07-23 14:17:30,034 | INFO     | train - Saved best model (epoch 20).
2025-07-23 14:17:30,040 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:17:30,047 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:17:30,055 | INFO     | model - Model moved to device: mps
2025-07-23 14:17:30,114 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:17:30,115 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:17:30,409 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:17:30,636 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_20_exported.onnx
2025-07-23 14:17:30,637 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:17:40,995 | INFO     | train - E021  train:6.813e-02  val:6.658e-02  lr:1.00e-04  t:10.3s  ↓6.145e-03
2025-07-23 14:17:41,009 | INFO     | train - Saved best model (epoch 21).
2025-07-23 14:17:41,015 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:17:41,021 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:17:41,030 | INFO     | model - Model moved to device: mps
2025-07-23 14:17:41,086 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 189, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:17:41,086 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:17:41,314 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:17:41,540 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_21_exported.onnx
2025-07-23 14:17:41,540 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:23:46,699 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:23:46,699 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:23:46,699 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:23:46,757 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:23:46,867 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:23:46,871 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:23:46,980 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:23:46,983 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:23:46,985 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:23:46,997 | INFO     | dataset - Memory estimate: 0.03 GB needed, 6.29 GB safely available
2025-07-23 14:23:46,997 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:24:00,753 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:24:00,754 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:24:00,762 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.28 GB safely available
2025-07-23 14:24:00,762 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:24:03,496 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:24:03,496 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:24:03,509 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.40 GB safely available
2025-07-23 14:24:03,509 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:24:06,155 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:24:06,155 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:24:06,156 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:24:06,162 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:24:06,182 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:24:06,182 | INFO     | model - Model moved to device: mps
2025-07-23 14:24:06,792 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:24:06,792 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:24:06,792 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:24:06,827 | INFO     | train - Training for 100 epochs.
2025-07-23 14:24:42,585 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:35.8s  ↓inf
2025-07-23 14:24:42,599 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:24:42,606 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:24:42,612 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:24:42,626 | INFO     | model - Model moved to device: mps
2025-07-23 14:24:42,650 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:24:42,651 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:24:42,651 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:28:34,121 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:28:34,121 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:28:34,121 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:28:34,161 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:28:34,271 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:28:34,272 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:28:34,381 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:28:34,385 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:28:34,388 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:28:34,396 | INFO     | dataset - Memory estimate: 0.03 GB needed, 5.66 GB safely available
2025-07-23 14:28:34,397 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:28:47,325 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:28:47,325 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:28:47,334 | INFO     | dataset - Memory estimate: 0.01 GB needed, 5.87 GB safely available
2025-07-23 14:28:47,334 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:28:49,890 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:28:49,890 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:28:49,897 | INFO     | dataset - Memory estimate: 0.01 GB needed, 5.81 GB safely available
2025-07-23 14:28:49,897 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:28:52,477 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:28:52,477 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:28:52,479 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:28:52,484 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:28:52,500 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:28:52,500 | INFO     | model - Model moved to device: mps
2025-07-23 14:28:53,059 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:28:53,059 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:28:53,059 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:28:53,094 | INFO     | train - Training for 100 epochs.
2025-07-23 14:29:30,529 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:37.4s  ↓inf
2025-07-23 14:29:30,544 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:29:30,552 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:29:30,561 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:29:30,576 | INFO     | model - Model moved to device: mps
2025-07-23 14:29:30,594 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:29:30,594 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:29:30,594 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:29:41,156 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:10.6s  ↓1.283e+00
2025-07-23 14:29:41,168 | INFO     | train - Saved best model (epoch 2).
2025-07-23 14:29:41,180 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:29:41,186 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:29:41,195 | INFO     | model - Model moved to device: mps
2025-07-23 14:29:41,206 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:29:41,206 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:29:41,206 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:29:51,546 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:10.3s  ↓2.588e-01
2025-07-23 14:29:51,558 | INFO     | train - Saved best model (epoch 3).
2025-07-23 14:29:51,564 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:29:51,571 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:29:51,579 | INFO     | model - Model moved to device: mps
2025-07-23 14:29:51,592 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:29:51,592 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:29:51,592 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:01,939 | INFO     | train - E004  train:3.023e-01  val:2.620e-01  lr:1.00e-04  t:10.3s  ↓1.082e-01
2025-07-23 14:30:01,950 | INFO     | train - Saved best model (epoch 4).
2025-07-23 14:30:01,956 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:01,962 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:01,970 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:01,978 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:01,978 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:01,978 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:12,294 | INFO     | train - E005  train:2.266e-01  val:2.477e-01  lr:1.00e-04  t:10.3s  ↓1.429e-02
2025-07-23 14:30:12,307 | INFO     | train - Saved best model (epoch 5).
2025-07-23 14:30:12,312 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:12,319 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:12,327 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:12,336 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:12,337 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:12,337 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:22,680 | INFO     | train - E006  train:1.923e-01  val:1.699e-01  lr:1.00e-04  t:10.3s  ↓7.775e-02
2025-07-23 14:30:22,691 | INFO     | train - Saved best model (epoch 6).
2025-07-23 14:30:22,696 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:22,703 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:22,711 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:22,719 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:22,720 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:22,720 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:33,076 | INFO     | train - E007  train:1.740e-01  val:1.627e-01  lr:1.00e-04  t:10.4s  ↓7.240e-03
2025-07-23 14:30:33,088 | INFO     | train - Saved best model (epoch 7).
2025-07-23 14:30:33,095 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:33,101 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:33,109 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:33,120 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:33,120 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:33,120 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:43,467 | INFO     | train - E008  train:1.495e-01  val:1.457e-01  lr:1.00e-04  t:10.3s  ↓1.702e-02
2025-07-23 14:30:43,478 | INFO     | train - Saved best model (epoch 8).
2025-07-23 14:30:43,493 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:43,499 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:43,507 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:43,515 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:43,515 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:43,515 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:53,885 | INFO     | train - E009  train:1.288e-01  val:1.327e-01  lr:1.00e-04  t:10.4s  ↓1.302e-02
2025-07-23 14:30:53,898 | INFO     | train - Saved best model (epoch 9).
2025-07-23 14:30:53,911 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:30:53,917 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:30:53,925 | INFO     | model - Model moved to device: mps
2025-07-23 14:30:53,935 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:30:53,935 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:30:53,935 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:04,281 | INFO     | train - E010  train:1.197e-01  val:1.248e-01  lr:1.00e-04  t:10.3s  ↓7.808e-03
2025-07-23 14:31:04,292 | INFO     | train - Saved best model (epoch 10).
2025-07-23 14:31:04,298 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:31:04,304 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:31:04,312 | INFO     | model - Model moved to device: mps
2025-07-23 14:31:04,322 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:04,322 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:31:04,322 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:14,631 | INFO     | train - E011  train:1.101e-01  val:1.078e-01  lr:1.00e-04  t:10.3s  ↓1.705e-02
2025-07-23 14:31:14,644 | INFO     | train - Saved best model (epoch 11).
2025-07-23 14:31:14,649 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:31:14,656 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:31:14,662 | INFO     | model - Model moved to device: mps
2025-07-23 14:31:14,671 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:14,671 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:31:14,671 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:24,975 | INFO     | train - E012  train:1.037e-01  val:1.303e-01  lr:1.00e-04  t:10.3s
2025-07-23 14:31:35,322 | INFO     | train - E013  train:9.781e-02  val:1.023e-01  lr:1.00e-04  t:10.3s  ↓5.547e-03
2025-07-23 14:31:35,336 | INFO     | train - Saved best model (epoch 13).
2025-07-23 14:31:35,350 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:31:35,356 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:31:35,363 | INFO     | model - Model moved to device: mps
2025-07-23 14:31:35,373 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:35,373 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:31:35,373 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:45,812 | INFO     | train - E014  train:9.062e-02  val:9.664e-02  lr:1.00e-04  t:10.4s  ↓5.611e-03
2025-07-23 14:31:45,833 | INFO     | train - Saved best model (epoch 14).
2025-07-23 14:31:45,841 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:31:45,847 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:31:45,856 | INFO     | model - Model moved to device: mps
2025-07-23 14:31:45,865 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:45,865 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:31:45,865 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:56,196 | INFO     | train - E015  train:8.574e-02  val:9.138e-02  lr:1.00e-04  t:10.3s  ↓5.260e-03
2025-07-23 14:31:56,208 | INFO     | train - Saved best model (epoch 15).
2025-07-23 14:31:56,225 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:31:56,231 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:31:56,238 | INFO     | model - Model moved to device: mps
2025-07-23 14:31:56,249 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:31:56,249 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:31:56,249 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:06,617 | INFO     | train - E016  train:8.279e-02  val:7.981e-02  lr:1.00e-04  t:10.4s  ↓1.157e-02
2025-07-23 14:32:06,628 | INFO     | train - Saved best model (epoch 16).
2025-07-23 14:32:06,634 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:32:06,644 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:32:06,653 | INFO     | model - Model moved to device: mps
2025-07-23 14:32:06,661 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:06,661 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:32:06,661 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:16,980 | INFO     | train - E017  train:9.738e-02  val:9.085e-02  lr:1.00e-04  t:10.3s
2025-07-23 14:32:27,272 | INFO     | train - E018  train:8.006e-02  val:8.122e-02  lr:1.00e-04  t:10.3s
2025-07-23 14:32:37,595 | INFO     | train - E019  train:7.546e-02  val:8.657e-02  lr:1.00e-04  t:10.3s
2025-07-23 14:32:47,843 | INFO     | train - E020  train:7.190e-02  val:7.272e-02  lr:1.00e-04  t:10.2s  ↓7.093e-03
2025-07-23 14:32:47,856 | INFO     | train - Saved best model (epoch 20).
2025-07-23 14:32:47,862 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:32:47,868 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:32:47,877 | INFO     | model - Model moved to device: mps
2025-07-23 14:32:47,887 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:47,888 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:32:47,888 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:58,191 | INFO     | train - E021  train:6.813e-02  val:6.658e-02  lr:1.00e-04  t:10.3s  ↓6.145e-03
2025-07-23 14:32:58,202 | INFO     | train - Saved best model (epoch 21).
2025-07-23 14:32:58,207 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:32:58,213 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:32:58,221 | INFO     | model - Model moved to device: mps
2025-07-23 14:32:58,230 | ERROR    | model - torch.export failed: name 'sdpa_kernel' is not defined
2025-07-23 14:32:58,230 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:32:58,230 | ERROR    | model - Fallback export also failed: name 'sdpa_kernel' is not defined
2025-07-23 14:34:35,157 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:34:35,157 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:34:35,157 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:34:35,201 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:34:35,309 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:34:35,312 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:34:35,424 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:34:35,428 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:34:35,431 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:34:35,437 | INFO     | dataset - Memory estimate: 0.03 GB needed, 6.57 GB safely available
2025-07-23 14:34:35,437 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:34:49,736 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:34:49,736 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:34:49,748 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.44 GB safely available
2025-07-23 14:34:49,748 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:34:53,106 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:34:53,106 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:34:53,113 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.44 GB safely available
2025-07-23 14:34:53,113 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:34:56,272 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:34:56,272 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:34:56,273 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:34:56,284 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:34:56,315 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:34:56,315 | INFO     | model - Model moved to device: mps
2025-07-23 14:34:56,975 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:34:56,975 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:34:56,975 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:34:57,015 | INFO     | train - Training for 100 epochs.
2025-07-23 14:35:39,667 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:42.7s  ↓inf
2025-07-23 14:35:39,680 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:35:39,688 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:35:39,694 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:35:39,703 | INFO     | model - Model moved to device: mps
2025-07-23 14:35:39,855 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:35:39,855 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:35:40,273 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:35:40,682 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 14:35:40,683 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 14:39:35,966 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:39:35,967 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:39:35,967 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:39:36,009 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:39:36,123 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:39:36,128 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:39:36,242 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:39:36,242 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:39:36,245 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:39:36,252 | INFO     | dataset - Memory estimate: 0.03 GB needed, 5.53 GB safely available
2025-07-23 14:39:36,252 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:39:49,702 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:39:49,702 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:39:49,707 | INFO     | dataset - Memory estimate: 0.01 GB needed, 5.61 GB safely available
2025-07-23 14:39:49,707 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:39:52,446 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:39:52,446 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:39:52,454 | INFO     | dataset - Memory estimate: 0.01 GB needed, 5.54 GB safely available
2025-07-23 14:39:52,454 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:39:55,095 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:39:55,095 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:39:55,095 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:39:55,101 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:39:55,119 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:39:55,120 | INFO     | model - Model moved to device: mps
2025-07-23 14:39:55,671 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:39:55,671 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:39:55,671 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:39:55,706 | INFO     | train - Training for 100 epochs.
2025-07-23 14:40:36,924 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:41.2s  ↓inf
2025-07-23 14:40:36,937 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:40:36,945 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:40:36,951 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:40:36,960 | INFO     | model - Model moved to device: mps
2025-07-23 14:40:37,114 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:40:37,114 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:40:37,494 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:40:37,901 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 14:40:39,083 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_1_exported_optimized.onnx
2025-07-23 14:40:50,153 | INFO     | train - E002  train:1.107e+00  val:6.290e-01  lr:1.00e-04  t:11.1s  ↓1.283e+00
2025-07-23 14:40:50,165 | INFO     | train - Saved best model (epoch 2).
2025-07-23 14:40:50,170 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:40:50,176 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:40:50,184 | INFO     | model - Model moved to device: mps
2025-07-23 14:40:50,237 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:40:50,238 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:40:50,531 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:40:50,840 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_2_exported.onnx
2025-07-23 14:40:51,108 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_2_exported_optimized.onnx
2025-07-23 14:41:02,032 | INFO     | train - E003  train:4.795e-01  val:3.702e-01  lr:1.00e-04  t:10.9s  ↓2.588e-01
2025-07-23 14:41:02,043 | INFO     | train - Saved best model (epoch 3).
2025-07-23 14:41:02,049 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:41:02,055 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:41:02,069 | INFO     | model - Model moved to device: mps
2025-07-23 14:41:02,121 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:41:02,121 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:41:02,364 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:41:02,668 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_3_exported.onnx
2025-07-23 14:41:02,938 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_3_exported_optimized.onnx
2025-07-23 14:41:13,502 | INFO     | train - E004  train:3.023e-01  val:2.620e-01  lr:1.00e-04  t:10.6s  ↓1.082e-01
2025-07-23 14:41:13,513 | INFO     | train - Saved best model (epoch 4).
2025-07-23 14:41:13,519 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:41:13,524 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:41:13,532 | INFO     | model - Model moved to device: mps
2025-07-23 14:41:13,585 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:41:13,586 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:41:13,872 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:41:14,163 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_4_exported.onnx
2025-07-23 14:41:14,420 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_4_exported_optimized.onnx
2025-07-23 14:41:25,089 | INFO     | train - E005  train:2.266e-01  val:2.477e-01  lr:1.00e-04  t:10.7s  ↓1.429e-02
2025-07-23 14:41:25,102 | INFO     | train - Saved best model (epoch 5).
2025-07-23 14:41:25,108 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:41:25,114 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:41:25,122 | INFO     | model - Model moved to device: mps
2025-07-23 14:41:25,178 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:41:25,178 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:41:25,411 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:41:25,703 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_5_exported.onnx
2025-07-23 14:41:25,964 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_5_exported_optimized.onnx
2025-07-23 14:41:37,030 | INFO     | train - E006  train:1.923e-01  val:1.699e-01  lr:1.00e-04  t:11.1s  ↓7.775e-02
2025-07-23 14:41:37,042 | INFO     | train - Saved best model (epoch 6).
2025-07-23 14:41:37,048 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:41:37,054 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:41:37,063 | INFO     | model - Model moved to device: mps
2025-07-23 14:41:37,116 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:41:37,117 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:41:37,429 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:41:37,720 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_6_exported.onnx
2025-07-23 14:41:37,980 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_6_exported_optimized.onnx
2025-07-23 14:41:48,722 | INFO     | train - E007  train:1.740e-01  val:1.627e-01  lr:1.00e-04  t:10.7s  ↓7.240e-03
2025-07-23 14:41:48,732 | INFO     | train - Saved best model (epoch 7).
2025-07-23 14:41:48,739 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:41:48,744 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:41:48,752 | INFO     | model - Model moved to device: mps
2025-07-23 14:41:48,805 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:41:48,805 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:41:49,094 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:41:49,384 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_7_exported.onnx
2025-07-23 14:41:49,644 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_7_exported_optimized.onnx
2025-07-23 14:42:00,385 | INFO     | train - E008  train:1.495e-01  val:1.457e-01  lr:1.00e-04  t:10.7s  ↓1.702e-02
2025-07-23 14:42:00,397 | INFO     | train - Saved best model (epoch 8).
2025-07-23 14:42:00,404 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:42:00,410 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:42:00,419 | INFO     | model - Model moved to device: mps
2025-07-23 14:42:00,473 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:42:00,473 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:42:00,708 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:42:00,998 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_8_exported.onnx
2025-07-23 14:42:01,258 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_8_exported_optimized.onnx
2025-07-23 14:42:11,940 | INFO     | train - E009  train:1.288e-01  val:1.327e-01  lr:1.00e-04  t:10.7s  ↓1.302e-02
2025-07-23 14:42:11,953 | INFO     | train - Saved best model (epoch 9).
2025-07-23 14:42:11,958 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:42:11,964 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:42:11,974 | INFO     | model - Model moved to device: mps
2025-07-23 14:42:12,028 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:42:12,028 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:42:12,342 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:42:12,642 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_9_exported.onnx
2025-07-23 14:42:12,905 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_9_exported_optimized.onnx
2025-07-23 14:42:23,494 | INFO     | train - E010  train:1.197e-01  val:1.248e-01  lr:1.00e-04  t:10.6s  ↓7.808e-03
2025-07-23 14:42:23,507 | INFO     | train - Saved best model (epoch 10).
2025-07-23 14:42:23,513 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:42:23,519 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:42:23,528 | INFO     | model - Model moved to device: mps
2025-07-23 14:42:23,583 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:42:23,583 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:42:23,819 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:42:24,109 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_10_exported.onnx
2025-07-23 14:42:24,373 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_10_exported_optimized.onnx
2025-07-23 14:42:34,929 | INFO     | train - E011  train:1.101e-01  val:1.078e-01  lr:1.00e-04  t:10.5s  ↓1.705e-02
2025-07-23 14:42:34,943 | INFO     | train - Saved best model (epoch 11).
2025-07-23 14:42:34,948 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:42:34,954 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:42:34,963 | INFO     | model - Model moved to device: mps
2025-07-23 14:42:35,017 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:42:35,018 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:42:35,309 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:42:35,603 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_11_exported.onnx
2025-07-23 14:42:35,862 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_11_exported_optimized.onnx
2025-07-23 14:42:46,661 | INFO     | train - E012  train:1.037e-01  val:1.303e-01  lr:1.00e-04  t:10.8s
2025-07-23 14:42:57,526 | INFO     | train - E013  train:9.781e-02  val:1.023e-01  lr:1.00e-04  t:10.9s  ↓5.547e-03
2025-07-23 14:42:57,539 | INFO     | train - Saved best model (epoch 13).
2025-07-23 14:42:57,545 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:42:57,551 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:42:57,560 | INFO     | model - Model moved to device: mps
2025-07-23 14:42:57,614 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:42:57,614 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:42:57,850 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:42:58,175 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_13_exported.onnx
2025-07-23 14:42:58,459 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_13_exported_optimized.onnx
2025-07-23 14:43:09,027 | INFO     | train - E014  train:9.062e-02  val:9.664e-02  lr:1.00e-04  t:10.6s  ↓5.611e-03
2025-07-23 14:43:09,039 | INFO     | train - Saved best model (epoch 14).
2025-07-23 14:43:09,045 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:43:09,051 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:43:09,060 | INFO     | model - Model moved to device: mps
2025-07-23 14:43:09,115 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:43:09,115 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:43:09,420 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:43:09,713 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_14_exported.onnx
2025-07-23 14:43:09,973 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_14_exported_optimized.onnx
2025-07-23 14:43:20,615 | INFO     | train - E015  train:8.574e-02  val:9.138e-02  lr:1.00e-04  t:10.6s  ↓5.260e-03
2025-07-23 14:43:20,628 | INFO     | train - Saved best model (epoch 15).
2025-07-23 14:43:20,633 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:43:20,639 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:43:20,646 | INFO     | model - Model moved to device: mps
2025-07-23 14:43:20,700 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:43:20,700 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:43:20,938 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:43:21,231 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_15_exported.onnx
2025-07-23 14:43:21,497 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_15_exported_optimized.onnx
2025-07-23 14:43:32,296 | INFO     | train - E016  train:8.279e-02  val:7.981e-02  lr:1.00e-04  t:10.8s  ↓1.157e-02
2025-07-23 14:43:32,308 | INFO     | train - Saved best model (epoch 16).
2025-07-23 14:43:32,313 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:43:32,319 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:43:32,328 | INFO     | model - Model moved to device: mps
2025-07-23 14:43:32,385 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:43:32,385 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:43:32,704 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:43:33,009 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_16_exported.onnx
2025-07-23 14:43:33,275 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_16_exported_optimized.onnx
2025-07-23 14:43:44,101 | INFO     | train - E017  train:9.738e-02  val:9.085e-02  lr:1.00e-04  t:10.8s
2025-07-23 14:43:55,039 | INFO     | train - E018  train:8.006e-02  val:8.122e-02  lr:1.00e-04  t:10.9s
2025-07-23 14:44:06,124 | INFO     | train - E019  train:7.546e-02  val:8.657e-02  lr:1.00e-04  t:11.1s
2025-07-23 14:44:10,741 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 14:44:10,741 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 14:44:10,741 | INFO     | utils - Generating new dataset splits...
2025-07-23 14:44:10,786 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 14:44:10,912 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 14:44:10,914 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 14:44:11,025 | WARNING  | train - Using only 10% of the dataset.
2025-07-23 14:44:11,028 | INFO     | utils - Global random seed set to 42.
2025-07-23 14:44:11,031 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 14:44:11,036 | INFO     | dataset - Memory estimate: 0.03 GB needed, 5.14 GB safely available
2025-07-23 14:44:11,036 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:44:26,791 | INFO     | dataset - AtmosphericDataset initialized: 7000 samples from data/processed/train (mode: RAM)
2025-07-23 14:44:26,792 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 14:44:26,798 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.50 GB safely available
2025-07-23 14:44:26,798 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:44:29,968 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/val (mode: RAM)
2025-07-23 14:44:29,969 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 14:44:29,975 | INFO     | dataset - Memory estimate: 0.01 GB needed, 6.48 GB safely available
2025-07-23 14:44:29,975 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 14:44:33,180 | INFO     | dataset - AtmosphericDataset initialized: 1500 samples from data/processed/test (mode: RAM)
2025-07-23 14:44:33,180 | INFO     | train - Datasets ready – train:7,000  val:1,500  test:1,500
2025-07-23 14:44:33,182 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 14:44:33,188 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:44:33,203 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 14:44:33,203 | INFO     | model - Model moved to device: mps
2025-07-23 14:44:33,791 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 14:44:33,791 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 14:44:33,791 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 14:44:33,828 | INFO     | train - Training for 100 epochs.
2025-07-23 14:45:26,248 | INFO     | train - E001  train:1.563e+01  val:1.912e+00  lr:1.00e-04  t:52.4s  ↓inf
2025-07-23 14:45:26,263 | INFO     | train - Saved best model (epoch 1).
2025-07-23 14:45:26,275 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 14:45:26,286 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 14:45:26,294 | INFO     | model - Model moved to device: mps
2025-07-23 14:45:26,532 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 14:45:26,532 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 14:45:27,039 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 14:45:27,525 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 14:45:28,027 | INFO     | model - Simplified ONNX graph saved to: models/trained_model/best_model_epoch_1_exported_optimized.onnx
2025-07-23 15:15:10,701 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 15:15:10,701 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 15:15:10,701 | INFO     | utils - Generating new dataset splits...
2025-07-23 15:15:10,750 | INFO     | utils - Generated splits from 100000 profiles across 1 files: train=70000 (70.0%), val=15000 (15.0%), test=15000 (15.0%)
2025-07-23 15:15:10,872 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 15:15:10,875 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-23 15:15:10,876 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-23 15:15:10,876 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-23 15:15:10,876 | INFO     | normalizer - Starting statistics calculation from 70000 training samples...
2025-07-23 15:15:59,323 | INFO     | normalizer - Finished statistics calculation in 48.45s.
2025-07-23 15:15:59,466 | INFO     | normalizer - Statistics calculation complete.
2025-07-23 15:15:59,467 | INFO     | preprocess - Normalization metadata computed and saved in 48.59s.
2025-07-23 15:15:59,467 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-23 15:15:59,470 | INFO     | preprocess - Processing train split (70000 profiles)...
2025-07-23 15:16:47,814 | INFO     | preprocess - Completed train split in 48.35s.
2025-07-23 15:16:47,816 | INFO     | preprocess - Processing val split (15000 profiles)...
2025-07-23 15:16:57,748 | INFO     | preprocess - Completed val split in 9.93s.
2025-07-23 15:16:57,749 | INFO     | preprocess - Processing test split (15000 profiles)...
2025-07-23 15:17:07,604 | INFO     | preprocess - Completed test split in 9.86s.
2025-07-23 15:17:07,604 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-23 15:17:07,606 | INFO     | preprocess - Preprocessing completed successfully in 116.73s.
2025-07-23 15:17:07,720 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 15:17:07,732 | INFO     | dataset - Memory estimate: 0.27 GB needed, 15.52 GB safely available
2025-07-23 15:17:07,732 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:17:16,548 | INFO     | dataset - Loaded 10000/70000 samples into RAM
2025-07-23 15:17:25,233 | INFO     | dataset - Loaded 20000/70000 samples into RAM
2025-07-23 15:17:34,063 | INFO     | dataset - Loaded 30000/70000 samples into RAM
2025-07-23 15:17:42,753 | INFO     | dataset - Loaded 40000/70000 samples into RAM
2025-07-23 15:17:51,447 | INFO     | dataset - Loaded 50000/70000 samples into RAM
2025-07-23 15:18:00,252 | INFO     | dataset - Loaded 60000/70000 samples into RAM
2025-07-23 15:18:09,016 | INFO     | dataset - Loaded 70000/70000 samples into RAM
2025-07-23 15:18:09,016 | INFO     | dataset - AtmosphericDataset initialized: 70000 samples from data/processed/train (mode: RAM)
2025-07-23 15:18:09,016 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 15:18:09,022 | INFO     | dataset - Memory estimate: 0.06 GB needed, 15.37 GB safely available
2025-07-23 15:18:09,022 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:18:17,735 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 15:18:22,200 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/val (mode: RAM)
2025-07-23 15:18:22,200 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 15:18:22,208 | INFO     | dataset - Memory estimate: 0.06 GB needed, 15.30 GB safely available
2025-07-23 15:18:22,208 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:18:30,986 | INFO     | dataset - Loaded 10000/15000 samples into RAM
2025-07-23 15:18:35,447 | INFO     | dataset - AtmosphericDataset initialized: 15000 samples from data/processed/test (mode: RAM)
2025-07-23 15:18:35,447 | INFO     | train - Datasets ready – train:70,000  val:15,000  test:15,000
2025-07-23 15:18:35,447 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 15:18:35,454 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:18:35,476 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 15:18:35,476 | INFO     | model - Model moved to device: mps
2025-07-23 15:18:36,130 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 15:18:36,130 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 15:18:36,130 | INFO     | train - Effective batch size: 256 (accumulation: 1)
2025-07-23 15:18:36,164 | INFO     | train - Training for 100 epochs.
2025-07-23 15:20:28,802 | INFO     | train - E001  train:1.772e+00  val:1.152e-01  lr:1.00e-04  t:112.6s  ↓inf
2025-07-23 15:20:28,817 | INFO     | train - Saved best model (epoch 1).
2025-07-23 15:20:28,822 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:20:28,829 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:20:28,838 | INFO     | model - Model moved to device: mps
2025-07-23 15:20:28,980 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:20:28,980 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:20:29,328 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:20:29,644 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_1_exported.onnx
2025-07-23 15:20:29,644 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:22:12,210 | INFO     | train - E002  train:9.805e-02  val:9.853e-02  lr:1.00e-04  t:102.6s  ↓1.664e-02
2025-07-23 15:22:12,222 | INFO     | train - Saved best model (epoch 2).
2025-07-23 15:22:12,227 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:22:12,234 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:22:12,241 | INFO     | model - Model moved to device: mps
2025-07-23 15:22:12,291 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:22:12,292 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:22:12,566 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:22:12,796 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_2_exported.onnx
2025-07-23 15:22:12,796 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:23:55,434 | INFO     | train - E003  train:7.264e-02  val:5.231e-02  lr:1.00e-04  t:102.6s  ↓4.623e-02
2025-07-23 15:23:55,446 | INFO     | train - Saved best model (epoch 3).
2025-07-23 15:23:55,452 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:23:55,458 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:23:55,468 | INFO     | model - Model moved to device: mps
2025-07-23 15:23:55,520 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:23:55,520 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:23:55,746 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:23:55,978 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_3_exported.onnx
2025-07-23 15:23:55,978 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:25:38,598 | INFO     | train - E004  train:5.541e-02  val:4.521e-02  lr:1.00e-04  t:102.6s  ↓7.093e-03
2025-07-23 15:25:38,610 | INFO     | train - Saved best model (epoch 4).
2025-07-23 15:25:38,615 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:25:38,622 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:25:38,631 | INFO     | model - Model moved to device: mps
2025-07-23 15:25:38,682 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:25:38,682 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:25:38,958 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:25:39,189 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_4_exported.onnx
2025-07-23 15:25:39,190 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:27:21,720 | INFO     | train - E005  train:5.313e-02  val:3.969e-02  lr:1.00e-04  t:102.5s  ↓5.521e-03
2025-07-23 15:27:21,731 | INFO     | train - Saved best model (epoch 5).
2025-07-23 15:27:21,737 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:27:21,744 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:27:21,752 | INFO     | model - Model moved to device: mps
2025-07-23 15:27:21,803 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:27:21,803 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:27:22,082 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:27:22,311 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_5_exported.onnx
2025-07-23 15:27:22,311 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:29:04,806 | INFO     | train - E006  train:4.201e-02  val:3.730e-02  lr:1.00e-04  t:102.5s  ↓2.394e-03
2025-07-23 15:29:04,817 | INFO     | train - Saved best model (epoch 6).
2025-07-23 15:29:04,822 | INFO     | train - Creating a fresh, un-compiled model instance for export.
2025-07-23 15:29:04,830 | INFO     | model - PredictionModel created with 614,274 trainable parameters. Architecture: d_model=128, nhead=4, layers=3
2025-07-23 15:29:04,839 | INFO     | model - Model moved to device: mps
2025-07-23 15:29:04,889 | ERROR    | model - torch.export failed: Operator does not support running with fake tensors
  Explanation: 
  Hint: see https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0 for how to fix

  Developer debug context: unsupported operator: aten._transformer_encoder_layer_fwd.default


from user code:
   File "/Users/imalsky/Desktop/Problemulator/src/model.py", line 190, in forward
    x = layer(src=x, src_key_padding_mask=sequence_mask)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-07-23 15:29:04,889 | INFO     | model - Attempting fallback export without dynamic shapes...
2025-07-23 15:29:05,117 | WARNING  | model - Exported with static shapes as fallback
2025-07-23 15:29:05,393 | INFO     | model - ONNX model saved with dynamic batch size: models/trained_model/best_model_epoch_6_exported.onnx
2025-07-23 15:29:05,393 | INFO     | model - onnxsim not installed – skipping ONNX optimisation
2025-07-23 15:30:47,876 | INFO     | train - E007  train:3.478e-02  val:4.112e-02  lr:1.00e-04  t:102.5s
2025-07-23 15:38:15,114 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 15:38:15,114 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 15:38:15,114 | INFO     | utils - Generating new dataset splits...
2025-07-23 15:38:15,191 | INFO     | utils - Generated splits from 200000 profiles across 2 files: train=140000 (70.0%), val=30000 (15.0%), test=30000 (15.0%)
2025-07-23 15:38:15,441 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 15:38:15,442 | INFO     | preprocess - Configuration has changed or processed data not found. Starting preprocessing...
2025-07-23 15:38:15,442 | INFO     | hardware - Using Apple‑Silicon MPS device (may be slower than CUDA).
2025-07-23 15:38:15,442 | INFO     | normalizer - DataNormalizer initialized on device 'mps'.
2025-07-23 15:38:15,442 | INFO     | normalizer - Starting statistics calculation from 140000 training samples...
2025-07-23 15:39:51,742 | INFO     | normalizer - Finished statistics calculation in 96.30s.
2025-07-23 15:39:51,759 | INFO     | normalizer - Approximating quantiles for 'net_reflected_flux' using sample of 10,000,000 values (out of 10,500,000 total).
2025-07-23 15:39:51,885 | INFO     | normalizer - Approximating quantiles for 'net_thermal_flux' using sample of 10,000,000 values (out of 10,500,000 total).
2025-07-23 15:39:51,955 | INFO     | normalizer - Approximating quantiles for 'pressure_bar' using sample of 10,000,000 values (out of 10,500,000 total).
2025-07-23 15:39:51,963 | INFO     | normalizer - Statistics calculation complete.
2025-07-23 15:39:51,964 | INFO     | preprocess - Normalization metadata computed and saved in 96.52s.
2025-07-23 15:39:51,965 | INFO     | preprocess - Using device: cpu for normalization.
2025-07-23 15:39:51,984 | INFO     | preprocess - Processing train split (140000 profiles)...
2025-07-23 15:41:28,892 | INFO     | preprocess - Completed train split in 96.93s.
2025-07-23 15:41:28,898 | INFO     | preprocess - Processing val split (30000 profiles)...
2025-07-23 15:41:48,785 | INFO     | preprocess - Completed val split in 19.89s.
2025-07-23 15:41:48,790 | INFO     | preprocess - Processing test split (30000 profiles)...
2025-07-23 15:42:08,575 | INFO     | preprocess - Completed test split in 19.79s.
2025-07-23 15:42:08,576 | INFO     | preprocess - Saving preprocessing summary to data/processed/preprocessing_summary.txt
2025-07-23 15:42:08,577 | INFO     | preprocess - Preprocessing completed successfully in 233.13s.
2025-07-23 15:42:08,814 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 15:42:08,834 | INFO     | dataset - Memory estimate: 0.54 GB needed, 12.77 GB safely available
2025-07-23 15:42:08,835 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:42:17,709 | INFO     | dataset - Loaded 10000/140000 samples into RAM
2025-07-23 15:42:26,385 | INFO     | dataset - Loaded 20000/140000 samples into RAM
2025-07-23 15:42:35,084 | INFO     | dataset - Loaded 30000/140000 samples into RAM
2025-07-23 15:42:43,768 | INFO     | dataset - Loaded 40000/140000 samples into RAM
2025-07-23 15:42:52,501 | INFO     | dataset - Loaded 50000/140000 samples into RAM
2025-07-23 15:43:01,240 | INFO     | dataset - Loaded 60000/140000 samples into RAM
2025-07-23 15:43:09,991 | INFO     | dataset - Loaded 70000/140000 samples into RAM
2025-07-23 15:43:18,687 | INFO     | dataset - Loaded 80000/140000 samples into RAM
2025-07-23 15:43:27,437 | INFO     | dataset - Loaded 90000/140000 samples into RAM
2025-07-23 15:43:36,086 | INFO     | dataset - Loaded 100000/140000 samples into RAM
2025-07-23 15:43:44,859 | INFO     | dataset - Loaded 110000/140000 samples into RAM
2025-07-23 15:43:53,547 | INFO     | dataset - Loaded 120000/140000 samples into RAM
2025-07-23 15:44:02,243 | INFO     | dataset - Loaded 130000/140000 samples into RAM
2025-07-23 15:44:11,083 | INFO     | dataset - Loaded 140000/140000 samples into RAM
2025-07-23 15:44:11,084 | INFO     | dataset - AtmosphericDataset initialized: 140000 samples from data/processed/train (mode: RAM)
2025-07-23 15:44:11,084 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 15:44:11,095 | INFO     | dataset - Memory estimate: 0.11 GB needed, 12.80 GB safely available
2025-07-23 15:44:11,095 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:44:20,007 | INFO     | dataset - Loaded 10000/30000 samples into RAM
2025-07-23 15:44:28,689 | INFO     | dataset - Loaded 20000/30000 samples into RAM
2025-07-23 15:44:38,522 | INFO     | dataset - Loaded 30000/30000 samples into RAM
2025-07-23 15:44:38,523 | INFO     | dataset - AtmosphericDataset initialized: 30000 samples from data/processed/val (mode: RAM)
2025-07-23 15:44:38,523 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 15:44:38,533 | INFO     | dataset - Memory estimate: 0.11 GB needed, 12.75 GB safely available
2025-07-23 15:44:38,533 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 15:44:47,734 | INFO     | dataset - Loaded 10000/30000 samples into RAM
2025-07-23 15:44:56,544 | INFO     | dataset - Loaded 20000/30000 samples into RAM
2025-07-23 15:45:05,407 | INFO     | dataset - Loaded 30000/30000 samples into RAM
2025-07-23 15:45:05,407 | INFO     | dataset - AtmosphericDataset initialized: 30000 samples from data/processed/test (mode: RAM)
2025-07-23 15:45:05,407 | INFO     | train - Datasets ready – train:140,000  val:30,000  test:30,000
2025-07-23 15:45:05,407 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 15:45:05,427 | INFO     | model - PredictionModel created with 2,440,962 trainable parameters. Architecture: d_model=256, nhead=4, layers=3
2025-07-23 15:45:05,441 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 15:45:05,441 | INFO     | model - Model moved to device: mps
2025-07-23 15:45:06,051 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 15:45:06,051 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 15:45:06,051 | INFO     | train - Effective batch size: 512 (accumulation: 1)
2025-07-23 15:45:06,090 | INFO     | train - Training for 100 epochs.
2025-07-23 18:20:41,090 | INFO     | utils - Loading dataset splits from: data/dataset_splits.json
2025-07-23 18:20:41,090 | INFO     | utils - Could not load splits file. Reason: Splits file not found: data/dataset_splits.json. Generating new splits.
2025-07-23 18:20:41,090 | INFO     | utils - Generating new dataset splits...
2025-07-23 18:20:41,155 | INFO     | utils - Generated splits from 200000 profiles across 2 files: train=140000 (70.0%), val=30000 (15.0%), test=30000 (15.0%)
2025-07-23 18:20:41,378 | INFO     | utils - Saved generated splits to models/trained_model/splits_generated.json
2025-07-23 18:20:41,379 | INFO     | preprocess - Processed data is up-to-date based on configuration hash. Skipping preprocessing.
2025-07-23 18:20:41,607 | INFO     | dataset - Creating dataset from data/processed/train...
2025-07-23 18:20:41,621 | INFO     | dataset - Memory estimate: 0.54 GB needed, 15.24 GB safely available
2025-07-23 18:20:41,621 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 18:20:51,175 | INFO     | dataset - Loaded 10000/140000 samples into RAM
2025-07-23 18:20:59,812 | INFO     | dataset - Loaded 20000/140000 samples into RAM
2025-07-23 18:21:08,755 | INFO     | dataset - Loaded 30000/140000 samples into RAM
2025-07-23 18:21:17,446 | INFO     | dataset - Loaded 40000/140000 samples into RAM
2025-07-23 18:21:26,171 | INFO     | dataset - Loaded 50000/140000 samples into RAM
2025-07-23 18:21:34,392 | INFO     | dataset - Loaded 60000/140000 samples into RAM
2025-07-23 18:21:42,255 | INFO     | dataset - Loaded 70000/140000 samples into RAM
2025-07-23 18:21:50,380 | INFO     | dataset - Loaded 80000/140000 samples into RAM
2025-07-23 18:21:58,334 | INFO     | dataset - Loaded 90000/140000 samples into RAM
2025-07-23 18:22:06,530 | INFO     | dataset - Loaded 100000/140000 samples into RAM
2025-07-23 18:22:16,477 | INFO     | dataset - Loaded 110000/140000 samples into RAM
2025-07-23 18:22:26,272 | INFO     | dataset - Loaded 120000/140000 samples into RAM
2025-07-23 18:22:35,548 | INFO     | dataset - Loaded 130000/140000 samples into RAM
2025-07-23 18:22:44,187 | INFO     | dataset - Loaded 140000/140000 samples into RAM
2025-07-23 18:22:44,187 | INFO     | dataset - AtmosphericDataset initialized: 140000 samples from data/processed/train (mode: RAM)
2025-07-23 18:22:44,187 | INFO     | dataset - Creating dataset from data/processed/val...
2025-07-23 18:22:44,193 | INFO     | dataset - Memory estimate: 0.11 GB needed, 14.52 GB safely available
2025-07-23 18:22:44,193 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 18:22:52,440 | INFO     | dataset - Loaded 10000/30000 samples into RAM
2025-07-23 18:23:00,842 | INFO     | dataset - Loaded 20000/30000 samples into RAM
2025-07-23 18:23:09,597 | INFO     | dataset - Loaded 30000/30000 samples into RAM
2025-07-23 18:23:09,597 | INFO     | dataset - AtmosphericDataset initialized: 30000 samples from data/processed/val (mode: RAM)
2025-07-23 18:23:09,597 | INFO     | dataset - Creating dataset from data/processed/test...
2025-07-23 18:23:09,613 | INFO     | dataset - Memory estimate: 0.11 GB needed, 14.55 GB safely available
2025-07-23 18:23:09,614 | INFO     | dataset - Loading entire dataset into RAM...
2025-07-23 18:23:19,376 | INFO     | dataset - Loaded 10000/30000 samples into RAM
2025-07-23 18:23:29,168 | INFO     | dataset - Loaded 20000/30000 samples into RAM
2025-07-23 18:23:38,810 | INFO     | dataset - Loaded 30000/30000 samples into RAM
2025-07-23 18:23:38,810 | INFO     | dataset - AtmosphericDataset initialized: 30000 samples from data/processed/test (mode: RAM)
2025-07-23 18:23:38,810 | INFO     | train - Datasets ready – train:140,000  val:30,000  test:30,000
2025-07-23 18:23:38,810 | INFO     | train - Using DevicePrefetchLoader for MPS transfers
2025-07-23 18:23:38,830 | INFO     | model - PredictionModel created with 2,440,962 trainable parameters. Architecture: d_model=256, nhead=4, layers=3
2025-07-23 18:23:38,851 | INFO     | model - torch.compile is only enabled for CUDA devices.
2025-07-23 18:23:38,851 | INFO     | model - Model moved to device: mps
2025-07-23 18:23:39,466 | INFO     | train - Optimizer: adamw  lr=1.00e-04  wd=1.00e-05
2025-07-23 18:23:39,467 | INFO     | train - Using ReduceLROnPlateau scheduler.
2025-07-23 18:23:39,467 | INFO     | train - Effective batch size: 512 (accumulation: 1)
2025-07-23 18:23:39,505 | INFO     | train - Training for 100 epochs.
